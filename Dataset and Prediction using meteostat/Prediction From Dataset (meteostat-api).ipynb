{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Train): 135.83660020134994\n",
      "Mean Squared Error (Test): 92.0895123000136\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load data from the CSV file\n",
    "with open('rainfall_data.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    data = list(reader)\n",
    "\n",
    "# Convert data into features (X) and target (y)\n",
    "X = []\n",
    "y = []\n",
    "for row in data:\n",
    "    # Skip rows with missing values\n",
    "    if row['tavg'] == 'None' or row['tmin'] == 'None' or row['tmax'] == 'None' or row['wspd'] == 'None' or row['pres'] == 'None':\n",
    "        continue\n",
    "    # Extract features and target\n",
    "    features = [float(row['tavg']), float(row['tmin']), float(row['tmax']), float(row['wspd']), float(row['pres'])]\n",
    "    target = float(row['prcp'])\n",
    "    X.append(features)\n",
    "    y.append(target)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Mean Squared Error (Train): {mse_train}\")\n",
    "print(f\"Mean Squared Error (Test): {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score (Train): 0.12703172287605324\n",
      "R^2 Score (Test): 0.2052466659579295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R^2 score for train and test sets\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"R^2 Score (Train): {r2_train}\")\n",
    "print(f\"R^2 Score (Test): {r2_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted and Actual Rainfall:\n",
      "Day\t\tPredicted (mm)\tActual (mm)\tDifference (mm)\n",
      "1\t\t10.55\t\t7.90\t\t2.65\n",
      "2\t\t4.69\t\t0.00\t\t4.69\n",
      "3\t\t20.26\t\t39.60\t\t19.34\n",
      "4\t\t5.29\t\t3.80\t\t1.49\n",
      "5\t\t-0.07\t\t0.00\t\t0.07\n"
     ]
    }
   ],
   "source": [
    "# Select 5 random indices from the test set\n",
    "import random\n",
    "random.seed(42)\n",
    "indices = random.sample(range(len(X_test)), 5)\n",
    "\n",
    "# Predict rainfall for the selected days\n",
    "predicted_rainfall = model.predict(X_test[indices])\n",
    "actual_rainfall = y_test[indices]\n",
    "\n",
    "# Compare predicted and actual values\n",
    "print(\"Comparison of Predicted and Actual Rainfall:\")\n",
    "print(\"Day\\t\\tPredicted (mm)\\tActual (mm)\\tDifference (mm)\")\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"{i+1}\\t\\t{predicted_rainfall[i]:.2f}\\t\\t{actual_rainfall[i]:.2f}\\t\\t{abs(predicted_rainfall[i] - actual_rainfall[i]):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted and Actual Rainfall:\n",
      "Day\t\tPredicted\tActual\n",
      "1\t\tYes\t\tYes\n",
      "2\t\tYes\t\tNo\n",
      "3\t\tYes\t\tYes\n",
      "4\t\tYes\t\tYes\n",
      "5\t\tNo\t\tNo\n"
     ]
    }
   ],
   "source": [
    "# Define a threshold for classifying rainfall\n",
    "threshold = 0.1  # mm\n",
    "\n",
    "# Predict rainfall for the selected days\n",
    "predicted_rainfall = model.predict(X_test[indices])\n",
    "\n",
    "# Convert predicted rainfall to binary labels based on the threshold\n",
    "predicted_labels = ['Yes' if pred > threshold else 'No' for pred in predicted_rainfall]\n",
    "actual_labels = ['Yes' if actual > threshold else 'No' for actual in actual_rainfall]\n",
    "\n",
    "# Compare predicted and actual labels\n",
    "print(\"Comparison of Predicted and Actual Rainfall:\")\n",
    "print(\"Day\\t\\tPredicted\\tActual\")\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"{i+1}\\t\\t{predicted_labels[i]}\\t\\t{actual_labels[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predictions over 100 random days: 64.00%\n"
     ]
    }
   ],
   "source": [
    "# Select 100 random indices from the test set\n",
    "random.seed(42)\n",
    "indices = random.sample(range(len(X_test)), 100)\n",
    "\n",
    "# Predict rainfall for the selected days\n",
    "predicted_rainfall = model.predict(X_test[indices])\n",
    "\n",
    "# Convert predicted rainfall to binary labels based on the threshold\n",
    "predicted_labels = ['Yes' if pred > threshold else 'No' for pred in predicted_rainfall]\n",
    "actual_labels = ['Yes' if actual > threshold else 'No' for actual in y_test[indices]]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(1 for pred, actual in zip(predicted_labels, actual_labels) if pred == actual)\n",
    "accuracy = correct_predictions / len(indices)\n",
    "\n",
    "print(f\"Accuracy of predictions over 100 random days: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
